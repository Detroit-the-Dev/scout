{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Consolidation\n",
    "\n",
    "The aim of this notebook is to find groupings of column_names that refer to the same entity across different datasets. The approach we have taken is:\n",
    "1. Extract a list of unique column names and their frequency of occurrence\n",
    "2. Calculate a the similarity between every two column names, based on Levenshtein distance, stored in a matrix\n",
    "3. Run k-means clustering on the column names, using the similarity of a column name to every other column names (each row in the similarity matrix) as features, and using the column name frequency as weights\n",
    "4. Identify clusters with low average distance from the cluster centroids and inspect these clusters as groups of column names that refer to the same entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python39\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\julia\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\python39\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\python39\\lib\\site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\julia\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: fuzzywuzzy in c:\\python39\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: python-Levenshtein in c:\\python39\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\python39\\lib\\site-packages (from python-Levenshtein) (49.2.1)\n",
      "Requirement already satisfied: sklearn in c:\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\python39\\lib\\site-packages (from sklearn) (0.24.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.0.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "## Install dependencies\n",
    "!pip install pandas\n",
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuzzMatrix:\n",
    "    \"\"\"\n",
    "    A wrapper around a similarity matrix given a list of terms.\n",
    "    The underlying datastructure is a numpy matrix of dimensions len(terms) x len(terms)\n",
    "    \n",
    "    Scoring options:\n",
    "     - fuzz.ratio (default)\n",
    "     - fuzz.partial_ratio\n",
    "     - fuzz.token_sort_ratio\n",
    "     - fuzz.token_set_ratio\n",
    "    \n",
    "    See this link for descriptions of the different distance metrics:\n",
    "    https://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/\n",
    "    \"\"\"\n",
    "    def __init__(self, terms, scorer=fuzz.ratio, matrix=None):\n",
    "        \"\"\"\n",
    "        Create a FuzzyMatrix object from terms\n",
    "        \"\"\"\n",
    "        self.terms = terms\n",
    "        self.scorer = scorer\n",
    "        self.matrix = None\n",
    "        self.dict = {}\n",
    "        for i in range(len(terms)):\n",
    "            self.dict[terms[i]] = i\n",
    "        \n",
    "        if matrix == None:\n",
    "            self.calc_matrix()\n",
    "        else:\n",
    "            self.matrix = matrix\n",
    "    \n",
    "    def get_term(self, index: int):\n",
    "        if index >= len(self.terms):\n",
    "            return None\n",
    "        return self.terms[index]\n",
    "    \n",
    "    def score(self, term1, term2):\n",
    "        if term1 not in self.dict or term2 not in self.dict:\n",
    "            return None\n",
    "        \n",
    "        i = self.dict[term1]\n",
    "        j = self.dict[term2]\n",
    "        return self.matrix[i][j]\n",
    "    \n",
    "    def calc_matrix(self):\n",
    "        \"\"\"\n",
    "        Calculate the similarity matrix using the similarity matrix defined in self.scorer\n",
    "        \"\"\"\n",
    "        print(\"Building similarity matrix...\", flush=True)\n",
    "        size = len(self.terms)\n",
    "        self.matrix = np.empty((size, size))\n",
    "        for i in range(size):\n",
    "            for j in range(i, size):\n",
    "                similarity_score = self.scorer(self.terms[i], self.terms[j])\n",
    "                self.matrix[i][j] = similarity_score\n",
    "                self.matrix[j][i] = similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"\n",
    "    Wrapper around k-means clustering and the similarity matrix FuzzMatrix\n",
    "    \"\"\"\n",
    "    def __init__(self, terms, frequencies, scorer=fuzz.ratio):\n",
    "        \"\"\"\n",
    "        terms         : 1-d array-like list of unique terms to cluster\n",
    "        frequencies   : 1-d array-like list of frequencies/number of observations of each column name\n",
    "                        Frequencies will be used as the weights in K-means clustering\n",
    "        \n",
    "        terms and frequencies must be the same length\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        assert len(terms) == len(frequencies), \"terms and frequencies must be the same length\"\n",
    "        self.frequencies = frequencies\n",
    "        self.fuzz_matrix = FuzzMatrix(terms, scorer)\n",
    "        self.kmeans = None\n",
    "        self.clusters = {}\n",
    "        self.distances = []\n",
    "        self.sorted_distances = []\n",
    "    \n",
    "    def k_means(self, num_clusters: int = 100):\n",
    "        print(\"Running K-means clustering on {} terms with {} clusters...\".format(len(self.fuzz_matrix.terms), num_clusters), flush=True)\n",
    "        self.kmeans = KMeans(num_clusters).fit(self.fuzz_matrix.matrix, sample_weight=self.frequencies)\n",
    "        \n",
    "        # sort each terms into clusters -- key: label, value: [list of terms represented by index]\n",
    "        self.clusters = {}\n",
    "        for i in range(len(self.kmeans.labels_)):\n",
    "            label = self.kmeans.labels_[i]\n",
    "            if label not in self.clusters:\n",
    "                self.clusters[label] = [i]\n",
    "            else:\n",
    "                self.clusters[label].append(i)\n",
    "                \n",
    "        # calculate mean distance for each centroid\n",
    "        self.distances = self.calc_mean_distances(self.kmeans.labels_, self.kmeans.cluster_centers_, self.fuzz_matrix.matrix)\n",
    "        self.sorted_distances = sorted([(i, self.distances[i]) for i in range(len(self.distances))], key=lambda x : x[1])\n",
    "        \n",
    "        print(\"Finished running k-means and computing mean cluster spread\", flush=True)\n",
    "            \n",
    "    def calc_mean_distances(self, labels, centroids, data):\n",
    "        \"\"\"\n",
    "        Calculate the average distance for each centroid and return a list of tuples (cluster_index, avg distance)\n",
    "        \n",
    "        Returns a list of length len(centroids)\n",
    "        \"\"\"\n",
    "        distances = [0 for n in range(len(centroids))]\n",
    "        counts = [0 for n in range(len(centroids))]\n",
    "        \n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            row = data[i]\n",
    "            label = labels[i]\n",
    "            centroid = centroids[label]\n",
    "            dist = np.linalg.norm(row - centroid)\n",
    "            distances[label] += dist\n",
    "            counts[label] += 1\n",
    "        \n",
    "\n",
    "        return np.array(distances) / np.array(counts)\n",
    "        \n",
    "    def view_clusters(self, top=10):\n",
    "        \"\"\"\n",
    "        Print out the clusters with the lowest distance scores\n",
    "        \"\"\"\n",
    "        for i in range(top):\n",
    "            label = self.sorted_distances[i][0]\n",
    "            distance = self.sorted_distances[i][1]\n",
    "            cluster = self.clusters[label]\n",
    "            \n",
    "            print(\"Cluster\", i + 1)\n",
    "            print(\"  Mean distance:\", distance)\n",
    "            print(\"  Terms:\", [self.fuzz_matrix.get_term(x) for x in cluster])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code to run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file\n",
    "csv = \"columns_doe.csv\"\n",
    "df = pd.read_csv(csv)\n",
    "\n",
    "# Count occurence of each column name\n",
    "df_text = df.loc[df[\"columns_datatype\"] == \"Text\"]\n",
    "counts = df_text[\"column_name\"].value_counts()\n",
    "\n",
    "unique_column_names = counts.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Levenshtein distance K-means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building similarity matrix...\n",
      "Running K-means clustering on 3499 terms with 100 clusters...\n",
      "Finished running k-means and computing mean cluster spread\n"
     ]
    }
   ],
   "source": [
    "# Create and run k-means model\n",
    "model = Model(unique_column_names, counts.tolist())\n",
    "model.k_means(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View top X clusters with lowest mean distance to centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1\n",
      "  Mean distance: 2.098996940364457e-14\n",
      "  Terms: ['Year']\n",
      "Cluster 2\n",
      "  Mean distance: 78.33021134250498\n",
      "  Terms: ['TOTAL STUDENTS With 2 or More Suspensions or Removals', 'BLACK STUDENTS With 2 or More Suspensions or Removals', 'MULTI-RACIAL STUDENTS With 2 or More Suspensions or Removals', '11 STUDENTS With 2 or More Suspensions or Removals', 'UNKNOWN STUDENTS With 2 or More Suspensions or Removals', 'ASIAN STUDENTS With 2 or More Suspensions or Removals', 'AMERICAN INDIAN/ALASKAN NATIVE STUDENTS With 2 or More Suspensions or Removals', 'HISPANIC STUDENTS With 2 or More Suspensions or Removals', '10 STUDENTS With 2 or More Suspensions or Removals', '12 STUDENTS With 2 or More Suspensions or Removals', 'WHITE STUDENTS With 2 or More Suspensions or Removals', '13 STUDENTS With 2 or More Suspensions or Removals', 'ELL STUDENTS With 2 or More Suspensions or Removals', 'GEN ED STUDENTS With 2 or More Suspensions or Removals', '08 STUDENTS With 2 or More Suspensions or Removals', '15 STUDENTS With 2 or More Suspensions or Removals', '7 STUDENTS With 2 or More Suspensions or Removals', 'STH STUDENTS With 2 or More Suspensions or Removals', '20 STUDENTS With 2 or More Suspensions or Removals', '16 STUDENTS With 2 or More Suspensions or Removals', '9 STUDENTS With 2 or More Suspensions or Removals', '21 STUDENTS With 2 or More Suspensions or Removals', '06 STUDENTS With 2 or More Suspensions or Removals', '02 STUDENTS With 2 or More Suspensions or Removals', '5 STUDENTS With 2 or More Suspensions or Removals', '6 STUDENTS With 2 or More Suspensions or Removals', 'NON-STH STUDENTS With 2 or More Suspensions or Removals', 'SWD STUDENTS With 2 or More Suspensions or Removals', '09 STUDENTS With 2 or More Suspensions or Removals', '18 STUDENTS With 2 or More Suspensions or Removals', '8 STUDENTS With 2 or More Suspensions or Removals', 'FEMALE STUDENTS With 2 or More Suspensions or Removals', '17 STUDENTS With 2 or More Suspensions or Removals', 'NON-ELL STUDENTS With 2 or More Suspensions or Removals', '14 STUDENTS With 2 or More Suspensions or Removals', '01 STUDENTS With 2 or More Suspensions or Removals', 'MALE STUDENTS With 2 or More Suspensions or Removals', '07 STUDENTS With 2 or More Suspensions or Removals', '04 STUDENTS With 2 or More Suspensions or Removals', '19 STUDENTS With 2 or More Suspensions or Removals', '03 STUDENTS With 2 or More Suspensions or Removals', '0K STUDENTS With 2 or More Suspensions or Removals', '05 STUDENTS With 2 or More Suspensions or Removals']\n",
      "Cluster 3\n",
      "  Mean distance: 79.51898572212957\n",
      "  Terms: ['TOTAL SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'NON-ELL SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '16 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (1999)', '04 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '06 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'UNKNOWN SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '02 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '0K SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'NON-STH SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '13 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2002)', '10 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2005)', '6 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2009)', '7 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2008)', '10 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '19 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (1996)', 'GEN ED SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'STH SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'SWD SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'HISPANIC SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '03 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'WHITE SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'ASIAN SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '01 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'MULTI-RACIAL SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '12 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '12 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2003)', '20 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (1995)', '9 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2006)', '08 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '09 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'AMERICAN INDIAN/ALASKAN NATIVE SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'ELL SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '05 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '11 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '21 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (1994)', '5 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2010)', 'FEMALE SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '14 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2001)', '17 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (1998)', 'MALE SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', 'BLACK SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '18 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (1997)', '8 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2007)', '07 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted', '11 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2004)', '15 SUSPENSIONS Resulting from Incidents Where NYPD was Contacted (2000)']\n",
      "Cluster 4\n",
      "  Mean distance: 87.11225952511886\n",
      "  Terms: ['A56 Weapon Possession (Category I) P', 'A46 Weapon Possession (Category II) P', 'B58 Weapon Possession (Category I) P', 'B48 Weapon Possession (Category II) P', 'B48 Weapon Possession (Category II) S', 'A46 Weapon Possession (Category II) S', 'A56 Weapon Possession (Category I) S', 'B58 Weapon Possession (Category I) S', 'A56 Weapon Possession (Category I) R', 'B58 Weapon Possession (Category I) R', 'B48 Weapon Possession (Category II) R']\n",
      "Cluster 5\n",
      "  Mean distance: 135.02920191165785\n",
      "  Terms: ['selectioncriteria12_prog2', 'selectioncriteria9_prog4', 'selectioncriteria12_prog4', 'selectioncriteria6_prog5', 'selectioncriteria9_prog5', 'selectioncriteria3_prog4', 'selectioncriteria3_prog5', 'selectioncriteria11_prog6', 'selectioncriteria1_prog1', 'selectioncriteria7_prog6', 'selectioncriteria6_prog3', 'selectioncriteria4_prog4', 'selectioncriteria2_prog2', 'selectioncriteria3_prog1', 'selectioncriteria11_prog1', 'selectioncriteria12_prog3', 'selectioncriteria10_prog2', 'selectioncriteria2_prog3', 'selectioncriteria11_prog3', 'selectioncriteria8_prog4', 'selectioncriteria4_prog3', 'selectioncriteria12_prog5', 'selectioncriteria5_prog3', 'selectioncriteria7_prog1', 'selectioncriteria1_prog4', 'selectioncriteria1_prog2', 'selectioncriteria4_prog5', 'selectioncriteria4_prog2', 'selectioncriteria1_prog3', 'selectioncriteria8_prog6', 'selectioncriteria11_prog4', 'selectioncriteria6_prog4', 'selectioncriteria8_prog5', 'selectioncriteria6_prog6', 'selectioncriteria6_prog1', 'selectioncriteria9_prog2', 'selectioncriteria7_prog5', 'selectioncriteria10_prog1', 'selectioncriteria5_prog5', 'selectioncriteria8_prog1', 'selectioncriteria3_prog2', 'selectioncriteria8_prog3', 'selectioncriteria4_prog6', 'selectioncriteria9_prog3', 'selectioncriteria5_prog1', 'selectioncriteria12_prog1', 'selectioncriteria3_prog6', 'selectioncriteria2_prog5', 'selectioncriteria6_prog2', 'selectioncriteria5_prog6', 'selectioncriteria2_prog1', 'selectioncriteria10_prog4', 'selectioncriteria11_prog2', 'selectioncriteria7_prog2', 'selectioncriteria4_prog1', 'selectioncriteria1_prog6', 'selectioncriteria2_prog4', 'selectioncriteria3_prog3', 'selectioncriteria5_prog2', 'selectioncriteria1_prog5', 'selectioncriteria7_prog4', 'selectioncriteria2_prog6', 'selectioncriteria10_prog6', 'selectioncriteria11_prog5', 'selectioncriteria9_prog1', 'selectioncriteria5_prog4', 'selectioncriteria7_prog3', 'selectioncriteria10_prog3', 'selectioncriteria8_prog2', 'selectioncriteria12_prog6', 'selectioncriteria9_prog6', 'selectioncriteria10_prog5']\n",
      "Cluster 6\n",
      "  Mean distance: 147.1566517106947\n",
      "  Terms: ['grade9swdfilledflag9', 'grade9gefilledflag2', 'grade9swdfilledflag1', 'grade9swdfilledflag6', 'grade9gefilledflag9', 'grade9swdfilledflag5', 'grade9swdfilledflag7', 'grade9gefilledflag4', 'grade9swdfilledflag8', 'grade9gefilledflag7', 'grade9swdfilledflag2', 'grade9swdfilledflag4', 'grade9swdfilledflag3', 'grade9gefilledflag8', 'grade9gefilledflag5', 'grade9gefilledflag6', 'grade9swdfilledflag10', 'grade9gefilledflag3', 'grade9gefilledflag1', 'grade9gefilledflag10']\n",
      "Cluster 7\n",
      "  Mean distance: 150.87792907025403\n",
      "  Terms: ['requirement4_7', 'requirement7_9', 'requirement5_7', 'requirement5_2', 'requirement7_4', 'requirement6_9', 'requirement5_4', 'requirement4_6', 'requirement2_4', 'requirement7_2', 'requirement2_8', 'requirement4_2', 'requirement7_6', 'requirement8_9', 'requirement7_3', 'requirement4_9', 'requirement8_4', 'requirement4_5', 'requirement3_2', 'requirement3_5', 'requirement8_2', 'requirement6_2', 'requirement2_7', 'requirement3_7', 'requirement8_3', 'requirement2_6', 'requirement8_7', 'requirement3_3', 'requirement6_5', 'requirement6_8', 'requirement5_9', 'requirement6_7', 'requirement3_4', 'requirement7_8', 'requirement3_8', 'requirement8_6', 'requirement6_6', 'requirement3_6', 'requirement5_8', 'requirement2_2', 'requirement6_4', 'requirement8_5', 'requirement4_8', 'requirement8_8', 'requirement5_3', 'requirement3_9', 'requirement7_5', 'requirement5_6', 'requirement5_5', 'requirement2_9', 'requirement2_5', 'requirement2_3', 'requirement6_3', 'requirement4_3', 'requirement7_7', 'requirement9_8', 'requirement9_5', 'requirement4_4', 'requirement9_4', 'requirement9_3', 'requirement9_7', 'requirement9_9', 'requirement9_6', 'requirement9_2']\n",
      "Cluster 8\n",
      "  Mean distance: 152.9657381016284\n",
      "  Terms: ['requirement2_1', 'requirement1_9', 'requirement1_6', 'requirement7_1', 'requirement7_10', 'requirement8_10', 'requirement4_1', 'requirement1_7', 'requirement3_1', 'requirement2_10', 'requirement5_10', 'requirement5_1', 'requirement1_1', 'requirement1_2', 'requirement6_10', 'requirement1_8', 'requirement1_3', 'requirement1_10', 'requirement6_1', 'requirement8_1', 'requirement1_4', 'requirement4_10', 'requirement1_5', 'requirement3_10', 'requirement10_8', 'requirement12_9', 'requirement10_10', 'requirement12_1', 'requirement10_4', 'requirement10_9', 'requirement9_1', 'requirement11_8', 'requirement11_5', 'requirement10_3', 'requirement10_2', 'requirement12_10', 'requirement9_10', 'requirement11_10', 'requirement10_1', 'requirement12_3', 'requirement12_2', 'requirement12_6', 'requirement12_7', 'requirement11_9', 'requirement10_6', 'requirement11_4', 'requirement12_4', 'requirement12_8', 'requirement11_6', 'requirement11_1', 'requirement12_5', 'requirement11_3', 'requirement10_5', 'requirement10_7', 'requirement11_2', 'requirement11_7']\n",
      "Cluster 9\n",
      "  Mean distance: 166.94047960767068\n",
      "  Terms: ['5 SUPERINTENDENT', '12 SUPERINTENDENT', '11 SUPERINTENDENT', '10 SUPERINTENDENT', 'ELL SUPERINTENDENT', '2 SUPERINTENDENT', '8 SUPERINTENDENT', '01 SUPERINTENDENT', '19 SUPERINTENDENT', '90 SUPERINTENDENT', '9 SUPERINTENDENT', '45 SUPERINTENDENT', '05 SUPERINTENDENT', '17 SUPERINTENDENT', '7 SUPERINTENDENT', '13 SUPERINTENDENT', '4 SUPERINTENDENT', '02 SUPERINTENDENT', 'SWD SUPERINTENDENT', '3 SUPERINTENDENT', '14 SUPERINTENDENT', '20 SUPERINTENDENT', '21 SUPERINTENDENT', '31-44 SUPERINTENDENT', '30 SUPERINTENDENT', '22 SUPERINTENDENT', 'MALE SUPERINTENDENT', 'GEN ED SUPERINTENDENT', '6 SUPERINTENDENT', '08 SUPERINTENDENT', '06 SUPERINTENDENT', '07 SUPERINTENDENT', '18 SUPERINTENDENT', 'STH SUPERINTENDENT', '15 SUPERINTENDENT', '6-10 SUPERINTENDENT', 'NON-ELL SUPERINTENDENT', 'SUPERINTENDENT', 'FEMALE SUPERINTENDENT', '16 SUPERINTENDENT', '61-89 SUPERINTENDENT', '04 SUPERINTENDENT', 'NON-STH SUPERINTENDENT', '11-29 SUPERINTENDENT', '180 SUPERINTENDENT', '0 SUPERINTENDENT', '0K SUPERINTENDENT', '60 SUPERINTENDENT', '03 SUPERINTENDENT', '46-59 SUPERINTENDENT', '09 SUPERINTENDENT', '1 SUPERINTENDENT']\n",
      "Cluster 10\n",
      "  Mean distance: 167.39876035945608\n",
      "  Terms: ['admissionspriority11', 'admissionspriority48', 'admissionspriority29', 'admissionspriority37', 'admissionspriority32', 'admissionspriority42', 'admissionspriority33', 'admissionspriority16', 'admissionspriority45', 'admissionspriority26', 'admissionspriority210', 'admissionspriority12', 'admissionspriority34', 'admissionspriority46', 'admissionspriority15', 'admissionspriority28', 'admissionspriority38', 'admissionspriority410', 'admissionspriority43', 'admissionspriority17', 'admissionspriority41', 'admissionspriority36', 'admissionspriority310', 'admissionspriority18', 'admissionspriority31', 'admissionspriority39', 'admissionspriority22', 'admissionspriority27', 'admissionspriority24', 'admissionspriority19', 'admissionspriority21', 'admissionspriority110', 'admissionspriority49', 'admissionspriority35', 'admissionspriority44', 'admissionspriority14', 'admissionspriority25', 'admissionspriority47', 'admissionspriority23', 'admissionspriority13', 'admissionspriority56', 'admissionspriority74', 'admissionspriority710', 'admissionspriority55', 'admissionspriority58', 'admissionspriority66', 'admissionspriority510', 'admissionspriority77', 'admissionspriority59', 'admissionspriority65', 'admissionspriority52', 'admissionspriority76', 'admissionspriority54', 'admissionspriority68', 'admissionspriority57', 'admissionspriority64', 'admissionspriority61', 'admissionspriority69', 'admissionspriority62', 'admissionspriority78', 'admissionspriority51', 'admissionspriority71', 'admissionspriority67', 'admissionspriority72', 'admissionspriority75', 'admissionspriority63', 'admissionspriority73', 'admissionspriority53', 'admissionspriority79', 'admissionspriority610', 'admissionsmethod_prog5', 'admissionsmethod_prog3', 'admissionsmethod_prog2', 'admissionsmethod_prog1', 'admissionsmethod_prog6', 'admissionsmethod_prog4']\n"
     ]
    }
   ],
   "source": [
    "model.view_clusters(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract column data from json files and write to csv\n",
    "\n",
    "This has already been done and saved to \"columns.csv\" and \"columns_doe.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_department(dataset):\n",
    "    \"\"\"\n",
    "    Given a dataset, return the department\n",
    "    \"\"\"\n",
    "    domain_metadata = dataset[\"classification\"][\"domain_metadata\"]\n",
    "    if domain_metadata == None:\n",
    "        return None\n",
    "    \n",
    "    department = \"Dataset-Information_Agency\"\n",
    "    for d in domain_metadata:\n",
    "        if d[\"key\"] == department:\n",
    "            return d[\"value\"].strip()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns(dataset):\n",
    "    \"\"\"\n",
    "    Given a dictionary representing a dataset, where each of the json files\n",
    "    in analysis/metadata is considered a list of datasets, retrieve a list of column details,\n",
    "    where each column is represented as a dictionary with the following keys:\n",
    "    {\"column_name\", \"column_field_name\", \"column_type\", \"dataset\", \"department\"}\n",
    "    \"\"\"\n",
    "    department = get_department(dataset)\n",
    "    dataset_name = dataset[\"resource\"][\"name\"]\n",
    "\n",
    "    columns_name = dataset[\"resource\"][\"columns_name\"]\n",
    "    columns_field_name = dataset[\"resource\"][\"columns_field_name\"]\n",
    "    columns_datatype = dataset[\"resource\"][\"columns_datatype\"]\n",
    "    \n",
    "    columns = []\n",
    "    for i in range(len(columns_name)):\n",
    "        column = {}\n",
    "        column[\"column_name\" ] = columns_name[i]\n",
    "        \n",
    "        if i < len(columns_field_name):\n",
    "            column[\"columns_field_name\"] = columns_field_name[i]\n",
    "        else:\n",
    "            column[\"columns_field_name\"] = None\n",
    "        if i < len(columns_datatype):\n",
    "            column[\"columns_datatype\"] = columns_datatype[i]\n",
    "        else:\n",
    "            column[\"columns_datatype\"] = None\n",
    "        \n",
    "        column[\"dataset\"] = dataset_name\n",
    "        column[\"department\"] = department\n",
    "    \n",
    "        columns.append(column)\n",
    "    \n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find all datasets from DOE\n",
    "def extract_column_data(json_filenames, save_as, department=None):\n",
    "    columns = []\n",
    "    for file in json_filenames:\n",
    "        file_json = None\n",
    "        with open(\"metadata\\\\\" + file) as f:\n",
    "            file_json = json.load(f)\n",
    "\n",
    "        for dataset in file_json:\n",
    "            dpt = get_department(dataset)\n",
    "            if department == None:\n",
    "                columns += get_columns(dataset)\n",
    "            elif dpt == department:\n",
    "                columns += get_columns(dataset)\n",
    "\n",
    "    df = pd.DataFrame(columns)\n",
    "    df.to_csv(save_as)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>columns_field_name</th>\n",
       "      <th>columns_datatype</th>\n",
       "      <th>dataset</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAT Writing Avg. Score</td>\n",
       "      <td>sat_writing_avg_score</td>\n",
       "      <td>Text</td>\n",
       "      <td>2012 SAT Results</td>\n",
       "      <td>Department of Education (DOE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCHOOL NAME</td>\n",
       "      <td>school_name</td>\n",
       "      <td>Text</td>\n",
       "      <td>2012 SAT Results</td>\n",
       "      <td>Department of Education (DOE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SAT Math Avg. Score</td>\n",
       "      <td>sat_math_avg_score</td>\n",
       "      <td>Text</td>\n",
       "      <td>2012 SAT Results</td>\n",
       "      <td>Department of Education (DOE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Num of SAT Test Takers</td>\n",
       "      <td>num_of_sat_test_takers</td>\n",
       "      <td>Text</td>\n",
       "      <td>2012 SAT Results</td>\n",
       "      <td>Department of Education (DOE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBN</td>\n",
       "      <td>dbn</td>\n",
       "      <td>Text</td>\n",
       "      <td>2012 SAT Results</td>\n",
       "      <td>Department of Education (DOE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18148</th>\n",
       "      <td>Description of Code</td>\n",
       "      <td>description_of_code</td>\n",
       "      <td>Text</td>\n",
       "      <td>2014-15 Discharge Reporting By Code - HS</td>\n",
       "      <td>Department of Education (DOE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18149</th>\n",
       "      <td>Total Enrolled Students</td>\n",
       "      <td>total_enrolled_students</td>\n",
       "      <td>Text</td>\n",
       "      <td>2014-15 Discharge Reporting By Code - HS</td>\n",
       "      <td>Department of Education (DOE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18150</th>\n",
       "      <td>Count of Students</td>\n",
       "      <td>count_of_students</td>\n",
       "      <td>Text</td>\n",
       "      <td>2014-15 Discharge Reporting By Code - HS</td>\n",
       "      <td>Department of Education (DOE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18151</th>\n",
       "      <td>Code Type</td>\n",
       "      <td>code_type</td>\n",
       "      <td>Text</td>\n",
       "      <td>2014-15 Discharge Reporting By Code - HS</td>\n",
       "      <td>Department of Education (DOE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18152</th>\n",
       "      <td>Geographic Unit</td>\n",
       "      <td>geographic_unit</td>\n",
       "      <td>Text</td>\n",
       "      <td>2014-15 Discharge Reporting By Code - HS</td>\n",
       "      <td>Department of Education (DOE)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18153 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   column_name       columns_field_name columns_datatype  \\\n",
       "0       SAT Writing Avg. Score    sat_writing_avg_score             Text   \n",
       "1                  SCHOOL NAME              school_name             Text   \n",
       "2          SAT Math Avg. Score       sat_math_avg_score             Text   \n",
       "3       Num of SAT Test Takers   num_of_sat_test_takers             Text   \n",
       "4                          DBN                      dbn             Text   \n",
       "...                        ...                      ...              ...   \n",
       "18148      Description of Code      description_of_code             Text   \n",
       "18149  Total Enrolled Students  total_enrolled_students             Text   \n",
       "18150        Count of Students        count_of_students             Text   \n",
       "18151                Code Type                code_type             Text   \n",
       "18152          Geographic Unit          geographic_unit             Text   \n",
       "\n",
       "                                        dataset                     department  \n",
       "0                              2012 SAT Results  Department of Education (DOE)  \n",
       "1                              2012 SAT Results  Department of Education (DOE)  \n",
       "2                              2012 SAT Results  Department of Education (DOE)  \n",
       "3                              2012 SAT Results  Department of Education (DOE)  \n",
       "4                              2012 SAT Results  Department of Education (DOE)  \n",
       "...                                         ...                            ...  \n",
       "18148  2014-15 Discharge Reporting By Code - HS  Department of Education (DOE)  \n",
       "18149  2014-15 Discharge Reporting By Code - HS  Department of Education (DOE)  \n",
       "18150  2014-15 Discharge Reporting By Code - HS  Department of Education (DOE)  \n",
       "18151  2014-15 Discharge Reporting By Code - HS  Department of Education (DOE)  \n",
       "18152  2014-15 Discharge Reporting By Code - HS  Department of Education (DOE)  \n",
       "\n",
       "[18153 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get list of json filenames in the metadata dir\n",
    "cwd = os.getcwd()\n",
    "metadata_dir = cwd + \"\\metadata\"\n",
    "json_filenames = [x for x in os.listdir(metadata_dir) if x[-4:] == \"json\"]\n",
    "\n",
    "extract_column_data(json_filenames, \"columns_test.csv\", department=\"Department of Education (DOE)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuzzy",
   "language": "python",
   "name": "fuzzy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
