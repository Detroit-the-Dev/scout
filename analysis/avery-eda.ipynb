{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA: NYC Open Data Common Column Names \n",
    "Hack day Q2 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns_df = pd.read_csv(\"nyc_columns_common.csv\", index_col=0)\n",
    "common_columns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the distribution of field types\n",
    "We should (probably?) only match field names if for columns with the same field type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns_df.field_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above, I would recommend the following mapping to identify similar field types\n",
    "def clean_field_types(column):\n",
    "    new_column = column.str.lower().str.replace('_', ' ')\n",
    "    return new_column.replace('calendar date', 'date')\n",
    "\n",
    "common_columns_df.field_type = clean_field_types(common_columns_df.field_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now these field types *appear* unique, so we can match on these first\n",
    "common_columns_df.field_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's investigate columns with field_type=date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common field names\n",
    "date_columns_df = common_columns_df[common_columns_df['field_type'] == 'date'].copy()\n",
    "date_columns_df.field_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main thing I notice here is that we need a simple text matching for things like `closed_date` <--> `date_closed`. The problem I foresee running into is that with some of the less-common columns like `event_date` we can try to map it onto something more common, but we don't know what other columns are in the dataset(s) along with it so we can't guarantee an injective mapping onto the column names and could end up with duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common column names w/ type='date'\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n",
    "sns.barplot(x=date_columns_df.field_name.value_counts().index, y=date_columns_df.field_name.value_counts().values)\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank field names by number of appearances\n",
    "field_name_counts = common_columns_df.field_name.value_counts()\n",
    "field_name_counts\n",
    "\n",
    "# Visualize top field names by # occurences\n",
    "n = 25\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4.5))\n",
    "sns.barplot(x=field_name_counts.iloc[:n].values, y=field_name_counts.iloc[:n].index, ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore most common human-readable (Socrata) names\n",
    "Within just these, it seems that zip & postal code should be investigated as a possible a match (in this specific case you'd need to watch out for 3 vs. 5-digit zips). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_counts = common_columns_df.name.value_counts()\n",
    "name_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4.5))\n",
    "sns.barplot(x=name_counts.iloc[:25].values, y=name_counts.iloc[:25].index, ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.matcher import Matcher\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# matcher = spacy.matcher.Matcher(nlp.vocab)\n",
    "\n",
    "# pattern = [{\"LOWER\": \"date\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"start\"}]\n",
    "# matcher.add(\"date\", None, pattern)\n",
    "\n",
    "# doc = nlp(\"date\")\n",
    "# matches = matcher(doc)\n",
    "\n",
    "# save = []\n",
    "# for match_id, start, end in matches:\n",
    "#     string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "#     span = doc[start:end]  # The matched span\n",
    "#     print(match_id, string_id, start, end, span.text)\n",
    "\n",
    "# print(matches)\n",
    "\n",
    "# color_patterns = [nlp(text) for text in ('red', 'green', 'yellow')]\n",
    "# product_patterns = [nlp(text) for text in common_date_cols.index]\n",
    "# material_patterns = [nlp(text) for text in ('silk', 'yellow fabric')]\n",
    "\n",
    "# matcher = spacy.matcher.PhraseMatcher(nlp.vocab)\n",
    "# matcher.add('COLOR', None, *color_patterns)\n",
    "# matcher.add('PRODUCT', None, *product_patterns)\n",
    "# matcher.add('MATERIAL', None, *material_patterns)\n",
    "\n",
    "# doc = nlp(' '.join(common_date_cols.index))\n",
    "# matches = matcher(doc)\n",
    "# for match_id, start, end in matches:\n",
    "#     rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
    "#     span = doc[start : end]  # get the matched slice of the doc\n",
    "#     print(rule_id, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
