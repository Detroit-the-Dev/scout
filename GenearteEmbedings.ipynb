{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './src/datasets.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-10c893d3f460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./src/datasets.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './src/datasets.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./src/datasets.json','r') as f:\n",
    "    datasets = json.load(f)\n",
    "    \n",
    "# datasets=datasets['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = requests.get('http://api.us.socrata.com/api/catalog/v1?domains=data.NJ.gov&search_context=data.NJ.GOV').json()\n",
    "total = page1['resultSetSize']\n",
    "pages = math.ceil(total/100)\n",
    "results = []\n",
    "for page in range(pages):\n",
    "    pageResults = requests.get(f'http://api.us.socrata.com/api/catalog/v1?domains=data.NJ.gov&search_context=data.NJ.GOV&offset={page*100}&limit=100').json()['results']\n",
    "    results.extend(pageResults)\n",
    "datasets= results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup ={\n",
    "}\n",
    "rlookup={\n",
    "}\n",
    "def read_corpus(datasets, tokens_only=False):\n",
    "    for index,dataset in enumerate(datasets):\n",
    "            tokens = gensim.utils.simple_preprocess(dataset['resource']['name'] + \" \" + dataset['resource']['description'])\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                lookup[dataset['resource']['id']] = index\n",
    "                rlookup[index] = dataset['resource']['id']\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [index])\n",
    "\n",
    "train_corpus = list(read_corpus(datasets))\n",
    "# test_corpus = list(read_corpus(lee_test_file, tokens_only=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13680468,  0.3919937 ,  0.00068124,  0.19463938,  0.16055907,\n",
       "       -0.4844915 , -0.03056372,  0.1686794 ,  0.15181491,  0.06501225,\n",
       "        0.09733491,  0.12010238,  0.16548626, -0.00288182,  0.00744367,\n",
       "        0.14353925,  0.2714717 ,  0.47075793, -0.13730116, -0.06070143,\n",
       "        0.14261241,  0.20349064,  0.29540244, -0.2549563 ,  0.02786489,\n",
       "       -0.380275  ,  0.02617319, -0.11347429,  0.08431723,  0.04695805,\n",
       "        0.01856744,  0.22756544,  0.07928962,  0.21188079, -0.21645992,\n",
       "        0.4807366 ,  0.04655745,  0.24805148, -0.27978277, -0.04452246,\n",
       "       -0.19175273, -0.53164047,  0.1932537 ,  0.244147  ,  0.11147839,\n",
       "        0.05284307,  0.30567372,  0.28306463, -0.23946309, -0.09730349],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model.infer_vector(train_corpus[0].words)\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a7mk-8suc'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0]['resource']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docForId' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c1eb57e74d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocForId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ic3t-wcy2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'docForId' is not defined"
     ]
    }
   ],
   "source": [
    "docForId('ic3t-wcy2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 4, 5, 234, 5]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [23,4,5]\n",
    "b = [234,5]\n",
    "a.extend(b)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for datasetid in lookup.keys():\n",
    "    inferred_vector = model.infer_vector(train_corpus[lookup[datasetid]].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=30)\n",
    "    sims = [ {'dataset': rlookup[sim[0]], 'similarity': sim[1]} for sim in sims]\n",
    "    results[datasetid] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('public/NJ_similarity_metrics.json', 'w') as f:\n",
    "    json.dump(results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'jign-uhe6', 'similarity': 0.6124996542930603},\n",
       " {'dataset': 'shpd-5q9m', 'similarity': 0.5990572571754456},\n",
       " {'dataset': 'i6bk-bwyv', 'similarity': 0.5953792333602905},\n",
       " {'dataset': 'i4kb-6ab6', 'similarity': 0.590259313583374},\n",
       " {'dataset': 'rgy2-tti8', 'similarity': 0.587500274181366},\n",
       " {'dataset': '2mhq-um7h', 'similarity': 0.5857139825820923},\n",
       " {'dataset': 'fx4z-5xg2', 'similarity': 0.5824402570724487},\n",
       " {'dataset': '799n-b76v', 'similarity': 0.5821795463562012},\n",
       " {'dataset': '9z9b-6hvk', 'similarity': 0.5805541276931763},\n",
       " {'dataset': 'c2g8-ercv', 'similarity': 0.579156756401062}]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['jign-uhe6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataset': 'jign-uhe6', 'similarity': 0.6124996542930603},\n",
       " {'dataset': 'shpd-5q9m', 'similarity': 0.5990572571754456},\n",
       " {'dataset': 'i6bk-bwyv', 'similarity': 0.5953792333602905},\n",
       " {'dataset': 'i4kb-6ab6', 'similarity': 0.590259313583374},\n",
       " {'dataset': 'rgy2-tti8', 'similarity': 0.587500274181366},\n",
       " {'dataset': '2mhq-um7h', 'similarity': 0.5857139825820923},\n",
       " {'dataset': 'fx4z-5xg2', 'similarity': 0.5824402570724487},\n",
       " {'dataset': '799n-b76v', 'similarity': 0.5821795463562012},\n",
       " {'dataset': '9z9b-6hvk', 'similarity': 0.5805541276931763},\n",
       " {'dataset': 'c2g8-ercv', 'similarity': 0.579156756401062}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['mnz3-dyi8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = requests.get(\"http://api.us.socrata.com/api/catalog/v1/domains\").json()['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dataset_list_chunk(domain, page,chunk_size):\n",
    "    offset= page*chunk_size\n",
    "    limit = chunk_size\n",
    "    url='https://api.us.socrata.com/api/catalog/v1?domains={domain}&search_context={domain}&offset={offset}&limit={limit}'\n",
    "    return requests.get(url.format(domain=domain, offset=offset,limit=limit)).json()['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size=100\n",
    "\n",
    "results={}\n",
    "for domain in domains:\n",
    "    datasets = []\n",
    "    print('doing ',domain['domain'])\n",
    "    total = domain['count']\n",
    "    for i in range(total//chunk_size +1): \n",
    "        datasets.extend(get_dataset_list_chunk(domain['domain'], 0 ,100))\n",
    "    results[domain['domain']]=datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_portal_datasets.json', 'w') as f:\n",
    "    json.dump(results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_portal_datasets.json') as f:\n",
    "    results = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All dataset document modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_lookup={}\n",
    "reverse_all_data_lookup={}\n",
    "index = 0\n",
    "\n",
    "def read_corpus():\n",
    "    for domain in results.keys():\n",
    "        for dataset in results[domain]:\n",
    "            dataset_id = dataset['resource']['id']\n",
    "            key = \"{domain}_{did}\".format(domain=domain, did=dataset_id)\n",
    "            all_data_lookup[key] = index \n",
    "            reverse_all_data_lookup[index] = key\n",
    "            description = dataset['resource']['description']\n",
    "            tokens = gensim.utils.simple_preprocess(dataset['resource']['name'] + \" \" + dataset['resource']['description'])\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, [index])\n",
    "train_corpus = list(read_corpus())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "all_model.build_vocab(train_corpus)\n",
    "all_model.train(train_corpus, total_examples=all_model.corpus_count, epochs=all_model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
